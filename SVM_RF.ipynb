{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34552109-5daa-4c28-9201-db60187dc124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>AX-574114010</th>\n",
       "      <th>AX-564298109</th>\n",
       "      <th>AX-564298112</th>\n",
       "      <th>AX-574114011</th>\n",
       "      <th>AX-574114014</th>\n",
       "      <th>AX-563423214</th>\n",
       "      <th>AX-575660822</th>\n",
       "      <th>AX-577073921</th>\n",
       "      <th>AX-564298209</th>\n",
       "      <th>...</th>\n",
       "      <th>AX-574130077</th>\n",
       "      <th>AX-574130060</th>\n",
       "      <th>AX-574130061</th>\n",
       "      <th>AX-574130062</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Plate</th>\n",
       "      <th>Status</th>\n",
       "      <th>WWt</th>\n",
       "      <th>Group</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0</td>\n",
       "      <td>F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-1002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0</td>\n",
       "      <td>F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-1003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0</td>\n",
       "      <td>F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-1005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0</td>\n",
       "      <td>F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0</td>\n",
       "      <td>F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>Y_988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.73</td>\n",
       "      <td>FLGS23</td>\n",
       "      <td>F2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>Y_991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.30</td>\n",
       "      <td>FLGS23</td>\n",
       "      <td>F2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>Y_992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.48</td>\n",
       "      <td>FLGS23</td>\n",
       "      <td>F2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>Y_995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.81</td>\n",
       "      <td>FLGS23</td>\n",
       "      <td>F2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>Y_998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Training</td>\n",
       "      <td>RU28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.54</td>\n",
       "      <td>FLGS23</td>\n",
       "      <td>F2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2423 rows Ã— 65900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  AX-574114010  AX-564298109  AX-564298112  AX-574114011  \\\n",
       "0     B-1000           0.0           0.0           0.0           0.0   \n",
       "1     B-1002           0.0           0.0           0.0           0.0   \n",
       "2     B-1003           0.0           0.0           0.0           1.0   \n",
       "3     B-1005           0.0           0.0           0.0           2.0   \n",
       "4     B-1006           0.0           0.0           0.0           2.0   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "2418   Y_988           0.0           0.0           0.0           1.0   \n",
       "2419   Y_991           1.0           1.0           0.0           0.0   \n",
       "2420   Y_992           0.0           0.0           0.0           1.0   \n",
       "2421   Y_995           0.0           0.0           0.0           0.0   \n",
       "2422   Y_998           2.0           2.0           0.0           0.0   \n",
       "\n",
       "      AX-574114014  AX-563423214  AX-575660822  AX-577073921  AX-564298209  \\\n",
       "0              NaN           0.0           0.0           0.0           0.0   \n",
       "1              2.0           0.0           0.0           2.0           2.0   \n",
       "2              1.0           0.0           0.0           0.0           1.0   \n",
       "3              2.0           0.0           0.0           2.0           1.0   \n",
       "4              2.0           0.0           0.0           2.0           2.0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2418           NaN           0.0           0.0           1.0           0.0   \n",
       "2419           2.0           0.0           0.0           0.0           0.0   \n",
       "2420           1.0           0.0           0.0           2.0           0.0   \n",
       "2421           2.0           0.0           0.0           0.0           0.0   \n",
       "2422           2.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      ...  AX-574130077  AX-574130060  AX-574130061  AX-574130062       Pop  \\\n",
       "0     ...           0.0           0.0           0.0           0.0  Training   \n",
       "1     ...           0.0           0.0           0.0           0.0  Training   \n",
       "2     ...           0.0           0.0           0.0           0.0  Training   \n",
       "3     ...           0.0           0.0           0.0           0.0  Training   \n",
       "4     ...           0.0           0.0           0.0           0.0  Training   \n",
       "...   ...           ...           ...           ...           ...       ...   \n",
       "2418  ...           0.0           0.0           0.0           0.0  Training   \n",
       "2419  ...           0.0           0.0           0.0           0.0  Training   \n",
       "2420  ...           0.0           0.0           0.0           0.0  Training   \n",
       "2421  ...           0.0           0.0           0.0           0.0  Training   \n",
       "2422  ...           0.0           0.0           0.0           0.0  Training   \n",
       "\n",
       "      Plate  Status    WWt   Group  Generation  \n",
       "0      RU11     0.0    NaN      F0          F0  \n",
       "1      RU10     0.0    NaN      F0          F0  \n",
       "2      RU10     0.0    NaN      F0          F0  \n",
       "3      RU11     0.0    NaN      F0          F0  \n",
       "4      RU10     1.0    NaN      F0          F0  \n",
       "...     ...     ...    ...     ...         ...  \n",
       "2418   RU28     1.0  12.73  FLGS23          F2  \n",
       "2419   RU28     1.0  11.30  FLGS23          F2  \n",
       "2420   RU28     0.0   9.48  FLGS23          F2  \n",
       "2421   RU28     1.0   7.81  FLGS23          F2  \n",
       "2422   RU28     1.0  10.54  FLGS23          F2  \n",
       "\n",
       "[2423 rows x 65900 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## probably need to allocate >16gb of CPU memory to load this csv\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "chunksize = 100\n",
    "\n",
    "list_of_dataframes = []\n",
    "\n",
    "for df in pd.read_csv('DarpaGenoPheno.csv', chunksize=chunksize, index_col=0):\n",
    "    list_of_dataframes.append(df)\n",
    "\n",
    "result = pd.concat(list_of_dataframes)\n",
    "df = result\n",
    "df\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "ax_columns = [col for col in df.columns if col.startswith('AX')]\n",
    "\n",
    "# Drop rows with missing 'Status' only (target must be known)\n",
    "df = df.dropna(subset=['Status'])\n",
    "\n",
    "# Impute missing values with column-wise mode\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[ax_columns] = imputer.fit_transform(df[ax_columns])\n",
    "\n",
    "df.to_csv('ImputedScaledData.csv', index=False)\n",
    "df\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b37b19-3cfc-4350-8d83-c63ec5dac6e0",
   "metadata": {},
   "source": [
    "## Can start here: import data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1cdd60-a0b1-4acb-9749-0be260791667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "chunksize = 100\n",
    "\n",
    "list_of_dataframes = []\n",
    "\n",
    "for df in pd.read_csv('ImputedScaledData.csv', chunksize=chunksize, index_col=0):\n",
    "    list_of_dataframes.append(df)\n",
    "\n",
    "result = pd.concat(list_of_dataframes)\n",
    "df = result\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60fdcd2-b35e-4f58-a101-3121885dc62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24f08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_columns = [col for col in df.columns if col.startswith('AX')]\n",
    "# len(ax_columns)\n",
    "X = df[ax_columns]\n",
    "y = df[\"Status\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e4bc5",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a3ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_preds = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM Results:\")\n",
    "print(classification_report(y_test, svm_preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for SVM\n",
    "cm_svm = confusion_matrix(y_test, svm_preds)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62933e32-dd9e-4e9b-86b4-eedd0692e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search\n",
    "import numpy as np\n",
    "\n",
    "C_values = [0.1, 1, 10, 100]\n",
    "gamma_values = ['scale', 'auto', 0.01, 0.1, 1]\n",
    "\n",
    "accuracy_matrix = np.zeros((len(C_values), len(gamma_values)))\n",
    "\n",
    "for i, C in enumerate(C_values):\n",
    "    for j, gamma in enumerate(gamma_values):\n",
    "        model = SVC(kernel='rbf', C=C, gamma=gamma, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        preds = model.predict(X_test_scaled)\n",
    "        accuracy_matrix[i, j] = accuracy_score(y_test, preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(accuracy_matrix, annot=True, fmt=\".3f\",\n",
    "            xticklabels=gamma_values, yticklabels=C_values,\n",
    "            cmap=\"viridis\")\n",
    "plt.title(\"SVM Accuracy for Different C and Gamma\")\n",
    "plt.xlabel(\"Gamma\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    # 'C': [0.1, 1, 10, 100],\n",
    "    # 'gamma': ['scale', 1, 0.1, 0.01],\n",
    "    'kernel': ['rbf']\n",
    "    # 'degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=3, n_jobs=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the test set with best model: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2fb35a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42feca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)  # no scaling needed\n",
    "\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(classification_report(y_test, rf_preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for RF\n",
    "cm_rf = confusion_matrix(y_test, rf_preds)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d04fad-66d3-459f-850d-2e06ca6a2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search\n",
    "import numpy as np\n",
    "\n",
    "n_estimators_list = [50, 100, 200, 500]\n",
    "max_depth_list = [None, 10, 20, 50]\n",
    "\n",
    "accuracy_matrix = np.zeros((len(n_estimators_list), len(max_depth_list)))\n",
    "\n",
    "for i, n_estimators in enumerate(n_estimators_list):\n",
    "    for j, max_depth in enumerate(max_depth_list):\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        preds = model.predict(X_test_scaled)\n",
    "        accuracy_matrix[i, j] = accuracy_score(y_test, preds)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(accuracy_matrix, annot=True, fmt=\".3f\",\n",
    "            xticklabels=[str(d) for d in max_depth_list],\n",
    "            yticklabels=n_estimators_list,\n",
    "            cmap=\"viridis\")\n",
    "plt.title(\"Random Forest Accuracy\\n(n_estimators vs. max_depth)\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"n_estimators\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bca614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]        # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_clf,  \n",
    "                           param_grid=param_grid,  \n",
    "                           cv=5,             \n",
    "                           scoring='accuracy',  \n",
    "                           n_jobs=-1,        \n",
    "                           verbose=3)        \n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the test set with best model: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b1ac9-4086-4384-b544-46230a4e7d47",
   "metadata": {},
   "source": [
    "## Attempted dimensionality reduction\n",
    "\n",
    "Use PCA with 100 components + variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ded94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_filtered = selector.fit_transform(X)\n",
    "print(X_filtered.shape)\n",
    "pca = PCA(n_components=200) \n",
    "X_filtered = pca.fit_transform(X_filtered)\n",
    "X_filtered.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c304255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_filtered, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "rf.fit(X_train_red, y_train_red)\n",
    "rf_preds = rf.predict(X_test_red)\n",
    "\n",
    "# Train SVM\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm.fit(X_train_red, y_train_red)\n",
    "svm_preds = svm.predict(X_test_red)\n",
    "\n",
    "# Evaluate\n",
    "rf_acc = accuracy_score(y_test_red, rf_preds)\n",
    "svm_acc = accuracy_score(y_test_red, svm_preds)\n",
    "rf_report = classification_report(y_test_red, rf_preds, output_dict=True)\n",
    "svm_report = classification_report(y_test_red, svm_preds, output_dict=True)\n",
    "\n",
    "rf_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cm = confusion_matrix(y_test, rf_preds)\n",
    "svm_cm = confusion_matrix(y_test, svm_preds)\n",
    "\n",
    "# Plot Random Forest confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot SVM confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

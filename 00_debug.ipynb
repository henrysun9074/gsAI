{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cefd0cf2",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41853503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 10:06:33,143 - INFO - Loading dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch path: ['/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/torch']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 1) Load dependencies and data\n",
    "# ---------------------------\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.frozen import FrozenEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"PyTorch path:\", torch.__path__ )\n",
    "\n",
    "logger.info(\"Loading dataset...\")\n",
    "chunksize = 100\n",
    "list_of_dataframes = []\n",
    "for df in pd.read_csv('DarpaQCGenoPheno.csv', chunksize=chunksize, index_col=0):\n",
    "    list_of_dataframes.append(df)\n",
    "df = pd.concat(list_of_dataframes)\n",
    "\n",
    "ids = df[\"ID\"].values\n",
    "ax_columns = [col for col in df.columns if col.startswith('AX')]\n",
    "X = df[ax_columns]\n",
    "y = df[\"Status\"]\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb94154",
   "metadata": {},
   "source": [
    "## Testing NN proba output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a5c8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df[\"ID\"].values  \n",
    "X = df[ax_columns].values\n",
    "y = df[\"Status\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test, id_train, id_test = train_test_split(\n",
    "    X, y, ids, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b71de51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 2.8400\n",
      "Epoch 2/20, Loss: 0.5109\n",
      "Epoch 3/20, Loss: 0.1881\n",
      "Epoch 4/20, Loss: 0.0817\n",
      "Epoch 5/20, Loss: 0.0283\n",
      "Epoch 6/20, Loss: 0.0102\n",
      "Epoch 7/20, Loss: 0.0074\n",
      "Epoch 8/20, Loss: 0.0079\n",
      "Epoch 9/20, Loss: 0.0237\n",
      "Epoch 10/20, Loss: 0.0634\n",
      "Epoch 11/20, Loss: 0.1137\n",
      "Epoch 12/20, Loss: 0.3005\n",
      "Epoch 13/20, Loss: 0.2760\n",
      "Epoch 14/20, Loss: 0.1159\n",
      "Epoch 15/20, Loss: 0.0557\n",
      "Epoch 16/20, Loss: 0.0276\n",
      "Epoch 17/20, Loss: 0.0362\n",
      "Epoch 18/20, Loss: 0.0068\n",
      "Epoch 19/20, Loss: 0.0011\n",
      "Epoch 20/20, Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),   \n",
    "            nn.Sigmoid()       \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "model = SimpleMLP(input_dim=X_train.shape[1]).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cf0aa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.574, AUC: 0.605, R-value: 0.160\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    probs = model(X_test_tensor.to(device))\n",
    "    probs = probs.squeeze().cpu().numpy()   \n",
    "    preds = (probs > 0.5).astype(int)  \n",
    "\n",
    "acc = accuracy_score(y_test, preds)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "r_val, _ = pearsonr(probs, y_test)\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}, AUC: {auc:.3f}, R-value: {r_val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "972fbeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TrueLabel</th>\n",
       "      <th>PredProb</th>\n",
       "      <th>PredClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O_1318</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P1334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y_520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.586152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.832218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>GS822</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>B-529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.417637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>P452</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>GS1289</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>GS396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.717784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  TrueLabel  PredProb  PredClass\n",
       "0      P444          0  0.019979          0\n",
       "1    O_1318          1  0.902031          1\n",
       "2     P1334          0  0.000052          0\n",
       "3     Y_520          0  0.586152          1\n",
       "4     B-463          1  0.832218          1\n",
       "..      ...        ...       ...        ...\n",
       "467   GS822          1  0.999996          1\n",
       "468   B-529          0  0.417637          0\n",
       "469    P452          1  0.991505          1\n",
       "470  GS1289          1  0.997775          1\n",
       "471   GS396          0  0.717784          1\n",
       "\n",
       "[472 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"ID\": id_test,\n",
    "    \"TrueLabel\": y_test,\n",
    "    \"PredProb\": probs,\n",
    "    \"PredClass\": preds\n",
    "})\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14790740",
   "metadata": {},
   "source": [
    "## Old Training Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0e002",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d4bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2) Define search spaces and run Bayesian optimization (smaller/fewer iterations)\n",
    "# ---------------------------\n",
    "\n",
    "models = [\"LR\", \"RF\", \"GB\"]\n",
    "\n",
    "def get_small_search_spaces():\n",
    "    return {\n",
    "        \"LR\": (\n",
    "            LogisticRegression(max_iter=200, solver=\"saga\"),\n",
    "            {\n",
    "                \"C\": Real(1e-2, 1.0, prior=\"log-uniform\"),\n",
    "                \"penalty\": Categorical([\"l1\", \"l2\"]),\n",
    "            },\n",
    "        ),\n",
    "        \"RF\": (\n",
    "            RandomForestClassifier(n_jobs=-1),\n",
    "            {\n",
    "                \"n_estimators\": Integer(50, 200),\n",
    "                \"max_depth\": Integer(2, 10),\n",
    "            },\n",
    "        ),\n",
    "        \"GB\": (\n",
    "            XGBClassifier(\n",
    "                tree_method=\"hist\",  \n",
    "                device=\"cuda\",\n",
    "                eval_metric=\"logloss\",\n",
    "            ),\n",
    "            {\n",
    "                \"n_estimators\": Integer(50, 200),\n",
    "                \"max_depth\": Integer(2, 6),\n",
    "                \"learning_rate\": Real(0.05, 0.3, prior=\"log-uniform\"),\n",
    "            },\n",
    "        ),\n",
    "        # \"MLP\": (\n",
    "        #     MLPClassifier(max_iter=200),\n",
    "        #     {\n",
    "        #         \"hidden_layer_sizes\": Categorical([32, 64, (32, 16), (64, 32), (128,)]),\n",
    "        #         \"alpha\": Real(1e-5, 1e-2, prior=\"log-uniform\"),\n",
    "        #         \"learning_rate_init\": Real(1e-3, 1e-2, prior=\"log-uniform\"),\n",
    "        #     },\n",
    "        # ),\n",
    "    }\n",
    "\n",
    "def tune_model(X, y, model_name, n_iter=5):\n",
    "    base_model, search_space = get_small_search_spaces()[model_name]\n",
    "    logger.info(f\"Bayesian optimization for {model_name}\")\n",
    "    opt = BayesSearchCV(\n",
    "        estimator=base_model,\n",
    "        search_spaces=search_space,\n",
    "        n_iter=n_iter,\n",
    "        cv=3,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "    )\n",
    "    opt.fit(X, y)\n",
    "    logger.info(f\"Best {model_name} params: {opt.best_params_}\")\n",
    "    return opt.best_estimator_\n",
    "\n",
    "tuned_models = {name: tune_model(X, y, name) for name in models}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc5c43a",
   "metadata": {},
   "source": [
    "### 3fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9f5748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 15:50:01,640 - INFO - Outer Fold 1/3\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "2025-09-03 15:52:21,120 - INFO - LR Fold 1 AUC=0.619\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "2025-09-03 15:52:22,055 - INFO - RF Fold 1 AUC=0.583\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:52:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/xgboost/core.py:729: UserWarning: [15:52:24] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "2025-09-03 15:52:24,450 - INFO - GB Fold 1 AUC=0.616\n",
      "2025-09-03 15:52:24,452 - INFO - Outer Fold 2/3\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "2025-09-03 15:54:36,086 - INFO - LR Fold 2 AUC=0.605\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "2025-09-03 15:54:36,873 - INFO - RF Fold 2 AUC=0.547\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:54:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "2025-09-03 15:54:39,168 - INFO - GB Fold 2 AUC=0.605\n",
      "2025-09-03 15:54:39,169 - INFO - Outer Fold 3/3\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "2025-09-03 15:56:47,334 - INFO - LR Fold 3 AUC=0.592\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "2025-09-03 15:56:48,229 - INFO - RF Fold 3 AUC=0.578\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:56:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/hpc/group/schultzlab/hs325/miniconda3/envs/gsAI/lib/python3.12/site-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "2025-09-03 15:56:50,532 - INFO - GB Fold 3 AUC=0.588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>true_label</th>\n",
       "      <th>fold</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>B-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535270</td>\n",
       "      <td>0.48538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.40678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-1002</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535270</td>\n",
       "      <td>0.48538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-1003</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.48538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-1005</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535270</td>\n",
       "      <td>0.48538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  true_label  fold        LR        RF       GB\n",
       "29     B-1           1     2  0.495726  0.535270  0.48538\n",
       "0   B-1000           0     1  0.208333  0.542857  0.40678\n",
       "0   B-1002           0     2  0.495726  0.535270  0.48538\n",
       "1   B-1003           0     2  0.495726  0.272727  0.48538\n",
       "2   B-1005           0     2  0.495726  0.535270  0.48538"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 3) Run simplified cross-validation (3 folds instead of 10)\n",
    "# ---------------------------\n",
    "skf_outer = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "all_preds = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf_outer.split(X, y)):\n",
    "    logger.info(f\"Outer Fold {fold+1}/3\")\n",
    "\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    ids_test = ids[test_idx]\n",
    "\n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.2, stratify=y_train_val, random_state=42\n",
    "    )\n",
    "\n",
    "    fold_df = pd.DataFrame({\"ID\": ids_test, \"true_label\": y_test, \"fold\": fold+1})\n",
    "\n",
    "    for name, tuned_model in tuned_models.items():\n",
    "        tuned_model.fit(X_train, y_train)\n",
    "        frozen = FrozenEstimator(tuned_model)\n",
    "        calibrated = CalibratedClassifierCV(frozen, method=\"isotonic\", cv=\"prefit\")\n",
    "        calibrated.fit(X_cal, y_cal)\n",
    "\n",
    "        probs = calibrated.predict_proba(X_test)[:, 1]\n",
    "        fold_df[name] = probs\n",
    "\n",
    "        auc = roc_auc_score(y_test, probs)\n",
    "        logger.info(f\"{name} Fold {fold+1} AUC={auc:.3f}\")\n",
    "\n",
    "    all_preds.append(fold_df)\n",
    "\n",
    "prob_df = pd.concat(all_preds, axis=0).sort_values(\"ID\")\n",
    "prob_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10fede",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19121688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 15:58:12,351 - INFO - Saved debug predictions to debug_predicted_probabilities.csv\n",
      "2025-09-03 15:58:12,367 - INFO - Saved LR model to models/debug/LR_debug_model.joblib\n",
      "2025-09-03 15:58:12,422 - INFO - Saved RF model to models/debug/RF_debug_model.joblib\n",
      "2025-09-03 15:58:12,433 - INFO - Saved GB model to models/debug/GB_debug_model.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>true_label</th>\n",
       "      <th>fold</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>B-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535270</td>\n",
       "      <td>0.485380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.406780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-1002</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535270</td>\n",
       "      <td>0.485380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-1003</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.485380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-1005</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535270</td>\n",
       "      <td>0.485380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>Y_988</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.491803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Y_991</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.535270</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Y_992</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.576642</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.602941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>Y_995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.402923</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Y_998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.709091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2357 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  true_label  fold        LR        RF        GB\n",
       "29      B-1           1     2  0.495726  0.535270  0.485380\n",
       "0    B-1000           0     1  0.208333  0.542857  0.406780\n",
       "0    B-1002           0     2  0.495726  0.535270  0.485380\n",
       "1    B-1003           0     2  0.495726  0.272727  0.485380\n",
       "2    B-1005           0     2  0.495726  0.535270  0.485380\n",
       "..      ...         ...   ...       ...       ...       ...\n",
       "782   Y_988           1     3  0.396552  0.432836  0.491803\n",
       "785   Y_991           1     2  0.571429  0.535270  0.538462\n",
       "783   Y_992           0     3  0.576642  0.531746  0.602941\n",
       "784   Y_995           1     3  0.402923  0.700000  0.727273\n",
       "785   Y_998           1     1  0.684211  0.585366  0.709091\n",
       "\n",
       "[2357 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 4) Save model output\n",
    "# ---------------------------\n",
    "# Save predictions\n",
    "# prob_df.to_csv(\"debug_predicted_probabilities.csv\", index=False)\n",
    "logger.info(\"Saved debug predictions to debug_predicted_probabilities.csv\")\n",
    "\n",
    "# Save models\n",
    "os.makedirs(\"models/debug\", exist_ok=True)\n",
    "for name, model in tuned_models.items():\n",
    "    path = os.path.join(\"models/debug/\", f\"{name}_debug_model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    logger.info(f\"Saved {name} model to {path}\")\n",
    "\n",
    "prob_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
